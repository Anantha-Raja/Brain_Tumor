{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sko.ACO'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VarianceThreshold\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msko\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mACO\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ACO\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msko\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mACO\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ACO\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msko\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mACO\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ACA  \u001b[38;5;66;03m# Ant Colony Optimization\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sko.ACO'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sko\n",
      "  Obtaining dependency information for sko from https://files.pythonhosted.org/packages/fe/cf/6cd183a6ffe53db8dabbbd98a8a8497f34d87924a3718deb3d47ae349ab5/sko-0.5.7-py3-none-any.whl.metadata\n",
      "  Downloading sko-0.5.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\gojan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sko) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\gojan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sko) (1.14.1)\n",
      "Downloading sko-0.5.7-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: sko\n",
      "Successfully installed sko-0.5.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sko\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCV+Pso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sko.ACO'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VarianceThreshold\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msko\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mACO\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ACO\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msko\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mACO\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ACO\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msko\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mACO\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ACA  \u001b[38;5;66;03m# Ant Colony Optimization\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sko.ACO'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from pyswarm import pso\n",
    "import time\n",
    "\n",
    "# Step 1: Load and preprocess the dataset\n",
    "features = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
    "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\",\n",
    "    \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
    "    \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\",\n",
    "    \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\",\n",
    "    \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n",
    "]\n",
    "\n",
    "df_train = pd.read_csv(\"NSL_KDD_Train (1).csv\", header=None, names=features)\n",
    "df_test = pd.read_csv(\"NSL_KDD_Test (1).csv\", header=None, names=features)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = [\"protocol_type\", \"service\", \"flag\"]\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_features:\n",
    "    df_train[col] = encoder.fit_transform(df_train[col])\n",
    "    df_test[col] = encoder.transform(df_test[col])\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(df_train.drop(columns=[\"label\"]))\n",
    "y_train = df_train[\"label\"].apply(lambda x: 1 if x == \"normal\" else 0)\n",
    "X_test = scaler.transform(df_test.drop(columns=[\"label\"]))\n",
    "y_test = df_test[\"label\"].apply(lambda x: 1 if x == \"normal\" else 0)\n",
    "\n",
    "# Step 2: Apply Variance Threshold to remove low-variance features\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X_train = selector.fit_transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# Step 3: Oversample minority class using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 4: Define PSO fitness function\n",
    "def fitness_function(features_selected):\n",
    "    selected_indices = np.where(features_selected > 0.5)[0]\n",
    "    if len(selected_indices) == 0:  # Avoid empty feature subsets\n",
    "        return 1.0  # Large error for invalid subsets\n",
    "    \n",
    "    X_train_selected = X_train_balanced[:, selected_indices]\n",
    "    X_test_selected = X_test[:, selected_indices]\n",
    "    \n",
    "    model = SVC(kernel='rbf', max_iter=500)\n",
    "    model.fit(X_train_selected, y_train_balanced)\n",
    "    accuracy = model.score(X_test_selected, y_test)\n",
    "    return 1 - accuracy  # Minimize error\n",
    "\n",
    "# Step 5: Run PSO for feature selection\n",
    "num_features = X_train.shape[1]\n",
    "lb = [0] * num_features\n",
    "ub = [1] * num_features\n",
    "\n",
    "start_time = time.time()\n",
    "best_features, _ = pso(fitness_function, lb, ub, swarmsize=20, maxiter=10)  # Increased iterations\n",
    "feature_selection_time = time.time() - start_time\n",
    "\n",
    "# Step 6: Train SVM on selected features\n",
    "selected_features_indices = np.where(best_features > 0.5)[0]\n",
    "X_train_selected = X_train_balanced[:, selected_features_indices]\n",
    "X_test_selected = X_test[:, selected_features_indices]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.001, 0.01, 0.1, 'scale'],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "grid_search = GridSearchCV(SVC(max_iter=1000), param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "y_pred = best_model.predict(X_test_selected)\n",
    "classification_report_final = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Metrics\n",
    "accuracy = classification_report_final[\"accuracy\"]\n",
    "precision = classification_report_final[\"1\"][\"precision\"]\n",
    "recall = classification_report_final[\"1\"][\"recall\"]\n",
    "f1_score = classification_report_final[\"1\"][\"f1-score\"]\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of Selected Features: {len(selected_features_indices)}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n",
    "print(f\"Feature Selection Time: {feature_selection_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM+ACO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import time\n",
    "\n",
    "# Load the dataset\n",
    "features = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
    "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\",\n",
    "    \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
    "    \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\",\n",
    "    \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\",\n",
    "    \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n",
    "]\n",
    "\n",
    "df_train = pd.read_csv(\"NSL_KDD_Train (1).csv\", header=None, names=features)\n",
    "df_test = pd.read_csv(\"NSL_KDD_Test (1).csv\", header=None, names=features)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = [\"protocol_type\", \"service\", \"flag\"]\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_features:\n",
    "    df_train[col] = encoder.fit_transform(df_train[col])\n",
    "    df_test[col] = encoder.transform(df_test[col])\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(df_train.drop(columns=[\"label\"]))\n",
    "y_train = df_train[\"label\"].apply(lambda x: 1 if x == \"normal\" else 0)\n",
    "X_test = scaler.transform(df_test.drop(columns=[\"label\"]))\n",
    "y_test = df_test[\"label\"].apply(lambda x: 1 if x == \"normal\" else 0)\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 1: Define the fitness function for ACO (for feature selection)\n",
    "def fitness_function(ant_solution):\n",
    "    # Extract selected features based on ant's solution\n",
    "    selected_indices = np.where(ant_solution > 0.5)[0]\n",
    "    if len(selected_indices) == 0:  # Avoid empty feature subsets\n",
    "        return 1.0  # Large error for invalid subsets\n",
    "    \n",
    "    X_train_selected = X_train_balanced[:, selected_indices]\n",
    "    X_test_selected = X_test[:, selected_indices]\n",
    "    \n",
    "    model = SVC(kernel='rbf', max_iter=500)\n",
    "    model.fit(X_train_selected, y_train_balanced)\n",
    "    accuracy = model.score(X_test_selected, y_test)\n",
    "    return 1 - accuracy  # Minimize error (maximize accuracy)\n",
    "\n",
    "# Step 2: Ant Colony Optimization (ACO) Parameters\n",
    "class ACO:\n",
    "    def __init__(self, n_features, fitness_function, n_ants=20, n_best=5, n_iter=10, pheromone_decay=0.95, pheromone_init=0.1, alpha=1, beta=2):\n",
    "        self.n_features = n_features\n",
    "        self.fitness_function = fitness_function\n",
    "        self.n_ants = n_ants\n",
    "        self.n_best = n_best\n",
    "        self.n_iter = n_iter\n",
    "        self.pheromone_decay = pheromone_decay\n",
    "        self.pheromone_init = pheromone_init\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "        # Initialize pheromone matrix\n",
    "        self.pheromone = np.ones((self.n_ants, self.n_features)) * self.pheromone_init\n",
    "        self.best_solution = None\n",
    "        self.best_fitness = float(\"inf\")\n",
    "\n",
    "    def run(self):\n",
    "        for _ in range(self.n_iter):\n",
    "            # Construct solutions for each ant\n",
    "            solutions = np.random.rand(self.n_ants, self.n_features) > 0.5\n",
    "            \n",
    "            # Evaluate fitness of all ants' solutions\n",
    "            fitness_values = np.array([self.fitness_function(solution) for solution in solutions])\n",
    "            \n",
    "            # Update the best solution\n",
    "            best_ant = np.argmin(fitness_values)\n",
    "            if fitness_values[best_ant] < self.best_fitness:\n",
    "                self.best_fitness = fitness_values[best_ant]\n",
    "                self.best_solution = solutions[best_ant]\n",
    "            \n",
    "            # Update pheromone levels\n",
    "            self.pheromone *= self.pheromone_decay  # Decay pheromone\n",
    "            for i in range(self.n_best):\n",
    "                ant = np.argmin(fitness_values)\n",
    "                self.pheromone[ant] += self.best_fitness / (1 + fitness_values[ant])  # Reinforce pheromone for best ants\n",
    "            \n",
    "        return self.best_solution, self.best_fitness\n",
    "\n",
    "# Step 3: Configure and run ACO for feature selection\n",
    "start_time = time.time()\n",
    "aco = ACO(n_features=X_train.shape[1], fitness_function=fitness_function, n_ants=20, n_best=5, n_iter=10)\n",
    "best_solution, _ = aco.run()\n",
    "\n",
    "feature_selection_time = time.time() - start_time\n",
    "\n",
    "# Step 4: Train SVM on selected features\n",
    "selected_features_indices = np.where(best_solution > 0.5)[0]\n",
    "X_train_selected = X_train_balanced[:, selected_features_indices]\n",
    "X_test_selected = X_test[:, selected_features_indices]\n",
    "\n",
    "# Train SVM\n",
    "model = SVC(kernel='rbf', max_iter=1000)\n",
    "model.fit(X_train_selected, y_train_balanced)\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# Step 5: Generate classification report\n",
    "classification_report_final = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Metrics\n",
    "accuracy = classification_report_final[\"accuracy\"]\n",
    "precision = classification_report_final[\"1\"][\"precision\"]\n",
    "recall = classification_report_final[\"1\"][\"recall\"]\n",
    "f1_score = classification_report_final[\"1\"][\"f1-score\"]\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of Selected Features: {len(selected_features_indices)}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n",
    "print(f\"Feature Selection Time: {feature_selection_time:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
